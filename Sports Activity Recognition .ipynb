{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Action_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DsX1dlifw90U",
        "CQDsmutv4nDB"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRmiAbb49WZ5"
      },
      "source": [
        "## Setting Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doexa9Qdt4WW",
        "outputId": "ec89c4cf-4462-43aa-eb66-96f7474e53ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install video-kf\n",
        "!pip install katna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting video-kf\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/2b/56c48babf39da35c5cc969b6106cf4e355da3577699a8fd7d765546dc1af/video_kf-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: opencv-python>=4 in /usr/local/lib/python3.6/dist-packages (from video-kf) (4.1.2.30)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.6/dist-packages (from video-kf) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from video-kf) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22->video-kf) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22->video-kf) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22->video-kf) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22->video-kf) (3.0.4)\n",
            "Installing collected packages: video-kf\n",
            "Successfully installed video-kf-0.0.3\n",
            "Collecting katna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/3e/5c2da199eea89f4698b46bb18b64a4e5d9f60cfaecf3d6165c45809e0923/katna-0.4.1.4-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 40kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from katna) (0.16.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from katna) (0.22.2.post1)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (from katna) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from katna) (1.4.1)\n",
            "Collecting moviepy>=1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/54/01a8c4e35c75ca9724d19a7e4de9dc23f0ceb8769102c7de056113af61c3/moviepy-1.0.3.tar.gz (388kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from katna) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from katna) (2.23.0)\n",
            "Requirement already satisfied: opencv-contrib-python>=3.4.7 in /usr/local/lib/python3.6/dist-packages (from katna) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->katna) (3.2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->katna) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->katna) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->katna) (2.5)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->katna) (7.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->katna) (0.17.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.1->katna) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy>=1.0.1->katna) (4.41.1)\n",
            "Collecting proglog<=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/ab/4cb19b578e1364c0b2d6efd6521a8b4b4e5c4ae6528041d31a2a951dd991/proglog-0.1.9.tar.gz\n",
            "Collecting imageio_ffmpeg>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c8/04c6b4a001b8ae7326fb83d6665af1ee58d6cc1acb421f8ea40d2678fe3c/imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9MB 112kB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->katna) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->katna) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->katna) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->katna) (2020.6.20)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->katna) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->katna) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->katna) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->katna) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->katna) (1.15.0)\n",
            "Building wheels for collected packages: moviepy, proglog\n",
            "  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for moviepy: filename=moviepy-1.0.3-cp36-none-any.whl size=110729 sha256=edf372a36375fda893bd15ba7d1ae4a3443e16e7b9cebecd663e9a622230ca0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/fe/1c/f4e6dca9e828d4b979c04e461d7fcc5b8e7bd35f947e665b65\n",
            "  Building wheel for proglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for proglog: filename=proglog-0.1.9-cp36-none-any.whl size=6149 sha256=e4a37494e0018bb132477540e536516685f6e0b10aaa4bb0226763f133284faa\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/56/60/1d0306a8d90b188af393c1812ddb502a8821b70917f82dcc00\n",
            "Successfully built moviepy proglog\n",
            "\u001b[31mERROR: moviepy 1.0.3 has requirement imageio<3.0,>=2.5; python_version >= \"3.4\", but you'll have imageio 2.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: proglog, imageio-ffmpeg, moviepy, katna\n",
            "  Found existing installation: moviepy 0.2.3.5\n",
            "    Uninstalling moviepy-0.2.3.5:\n",
            "      Successfully uninstalled moviepy-0.2.3.5\n",
            "Successfully installed imageio-ffmpeg-0.4.2 katna-0.4.1.4 moviepy-1.0.3 proglog-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4WzKmh2vqB2"
      },
      "source": [
        "#Importing Libraries\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "from Katna.video import Video\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo-r-80Iu3QN",
        "outputId": "af81596a-e35f-4879-de60-54731980d2ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsX1dlifw90U"
      },
      "source": [
        "##KEY FRAME EXTRACTION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T3b-6a9xJip"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import os \n",
        "from Katna.video import Video\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyhOCeKFkTIA"
      },
      "source": [
        "try:\n",
        "  os.mkdir(\"/content/Image_Data\")\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAWh4z9mVEQo",
        "outputId": "f238cd29-2b46-477b-b12b-69e96b51acc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "########### KEY FRAME EXTRACTION ###########\n",
        "base = \"/content/drive/My Drive/Action_Recognition/Training\"                                                               # Base  path\n",
        "dest = \"/content/drive/My Drive/Action_Recognition/Image_Data\"\n",
        "counter = 0\n",
        "len0 = 0\n",
        "classes = os.listdir(base)\n",
        "vd = Video()\n",
        "\n",
        "\n",
        "shutil.rmtree(dest)\n",
        "os.mkdir(dest)\n",
        "\n",
        "for action in classes:\n",
        "  print(\"Preparing class:\",action)\n",
        "  files = os.listdir(os.path.join(base,action))\n",
        "  os.mkdir(os.path.join(dest,action))\n",
        "  for file1 in files:\n",
        "    path_loc = os.path.join(os.path.join(base,action),file1)                                      # File  path\n",
        "    imgs = vd.extract_frames_as_images(no_of_frames = 3, file_path= path_loc) \n",
        "    imgs_g = []\n",
        "    for image in imgs:\n",
        "      x = (cv2.cvtColor((image), cv2.COLOR_BGR2GRAY))\n",
        "      imgs_g.append(np.expand_dims(x,axis = 2))\n",
        "    if len(imgs_g)>0:\n",
        "      if len(imgs_g)<3:\n",
        "        counter += 1\n",
        "        while(len(imgs_g)<3):\n",
        "          imgs_g.append(imgs_g[len(imgs_g)-1])\n",
        "      imgs_g = [torch.tensor(img) for img in imgs_g]\n",
        "      x = torch.cat(imgs_g, dim = 2)\n",
        "      cv2.imwrite(os.path.join(os.path.join(dest,action),file1)+'.png',np.float32(x))\n",
        "    else:\n",
        "      len0 += 1\n",
        "\n",
        "    \n",
        "    \n",
        "  \n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing class: Walking\n",
            "Preparing class: Diving\n",
            "Preparing class: Tennis\n",
            "Preparing class: Basketball\n",
            "Preparing class: Jumping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwX_G2P_nmfv",
        "outputId": "7122d2e8-959f-44da-f1c1-df4f987dc777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Number of videos with 0 frames:\",len0)\n",
        "print(\"Number of videos with <3 keyframes:\",counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of videos with 0 frames: 2\n",
            "Number of videos with <3 keyframes: 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bqpo5CDh5EB",
        "outputId": "d31fc3b4-e4e0-4645-a6e8-78d2c2a5d5da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Oct 19 12:40:58 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsAgjSYSvdxr"
      },
      "source": [
        "## Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oszH05JJwmQe"
      },
      "source": [
        "size = 224\n",
        "image_transforms = {\n",
        "    'train':transforms.Compose([\n",
        "        transforms.Resize(size=(size,size)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InGeJtMsvfRT",
        "outputId": "387f34d7-0bd8-43f3-ad3b-f3ce518653bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set the train, test and validation directory\n",
        "train_directory = '/content/drive/My Drive/Action_Recognition/Image_Data'\n",
        "\n",
        "\n",
        "# Setting batch size for training\n",
        "batch_size=64\n",
        "\n",
        "#Number of classes for the data\n",
        "num_classes = 5\n",
        "\n",
        "#Loading the data from the folders into the variable 'data'\n",
        "data = datasets.ImageFolder(root=train_directory, transform=image_transforms['train'])\n",
        "\n",
        "#Find out the size of the data\n",
        "train_data_size = len(data)\n",
        "print(train_data_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65CyNhmAxY2F",
        "outputId": "3020bc25-5f9a-4ef0-c99f-eae01b2a85f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data, test_data = torch.utils.data.random_split(data, [len(data) - int(0.1*len(data)), int(0.1*len(data))])\n",
        "print(len(train_data),len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "425 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMy8b9Swxuhn"
      },
      "source": [
        "test_data, val_data = torch.utils.data.random_split(test_data, [len(test_data) - int(0.5*len(test_data)), int(0.5*len(test_data))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8y0lgK_yaYa"
      },
      "source": [
        "# Create iterators for the Data loaded using DataLoader module\n",
        "train_loader = DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_data,batch_size=batch_size,shuffle=True)\n",
        "val_loader = DataLoader(val_data,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQDsmutv4nDB"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTRySu7P4-fj"
      },
      "source": [
        "from torchvision import transforms # To perform all the transforms on our data\n",
        "from torchvision import datasets #Used to load the data from the folders\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPYbVOIm44Pn"
      },
      "source": [
        "#define train\n",
        "\n",
        "def train(device, loader, model, criterion, optimizer):\n",
        "    train_loss_epoch = 0\n",
        "    train_accuracy_epoch = 0\n",
        "\n",
        "    model.train()\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        acc = 0\n",
        "        optimizer.zero_grad()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "\n",
        "        inds = torch.argmax(output, dim=1)\n",
        "        loss = criterion(output, y)\n",
        "        \n",
        "        acc = (inds == y).sum().item() / y.size(0)\n",
        "\n",
        "        train_accuracy_epoch += acc\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_epoch += loss.item()\n",
        "\n",
        "\n",
        "        # if step % 100 == 0:\n",
        "        #     print(\n",
        "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
        "        #     )\n",
        "\n",
        "  \n",
        "    return train_loss_epoch, train_accuracy_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZvKoswg-ChY"
      },
      "source": [
        "#define train\n",
        "\n",
        "def validate(device, loader, model):\n",
        "    val_loss_epoch = 0\n",
        "    val_accuracy_epoch = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for step, (x, y) in enumerate(loader):\n",
        "          acc = 0\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "\n",
        "          output = model(x)\n",
        "\n",
        "          inds = torch.argmax(output, dim=1)\n",
        "          loss = criterion(output, y)\n",
        "          \n",
        "          acc = (inds == y).sum().item() / y.size(0)\n",
        "\n",
        "          val_accuracy_epoch += acc\n",
        "\n",
        "          val_loss_epoch += loss.item()\n",
        "\n",
        "    \n",
        "      return val_loss_epoch, val_accuracy_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WEl5i3JAIze"
      },
      "source": [
        "def test(device, loader, model):\n",
        "    loss_epoch = 0\n",
        "    accuracy_epoch = 0\n",
        "    model.eval()\n",
        "    for step, (x, y) in enumerate(loader):\n",
        "        model.zero_grad()\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "\n",
        "        predicted = output.argmax(1)\n",
        "        acc = (predicted == y).sum().item() / y.size(0)\n",
        "        accuracy_epoch += acc\n",
        "\n",
        "        loss_epoch += loss.item()\n",
        "\n",
        "    return loss_epoch, accuracy_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K7kQQzsyo7e"
      },
      "source": [
        "# Load the pretrained resnet 50 model\n",
        "resnet50 = torchvision.models.resnet50(pretrained=True)\n",
        "device = 'cuda'\n",
        "\n",
        "fc_inputs = resnet50.fc.in_features\n",
        "\n",
        "for param in resnet50.parameters():\n",
        "    param.requires_grad=False\n",
        "\n",
        "#Replacing last layer with our layers\n",
        "resnet50.fc = nn.Sequential(\n",
        "    nn.Linear(fc_inputs,5),\n",
        "    nn.Softmax(dim=1)\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnjVIu9B8BG-"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jZEqVQp7-gQ",
        "outputId": "104c0180-2294-4d96-8838-8ebe4a038184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Oct 21 13:25:36 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBIExnX167kq",
        "outputId": "4504ce5c-46f1-4b94-8cdb-356e6fb161fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Define the optimizer and loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(resnet50.parameters(),lr = 0.001)\n",
        "epochs = 50\n",
        "device = 'cuda'\n",
        "resnet50.to(device)\n",
        "loss_epoch_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss_epoch, train_accuracy_epoch = train(device, train_loader, resnet50, criterion, optimizer)\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{epochs}]\\t Train Loss: {train_loss_epoch / len(train_loader)}\\t Train Accuracy: {train_accuracy_epoch / len(train_loader)}\")\n",
        "\n",
        "    loss_epoch, accuracy_epoch = validate(device, val_loader, resnet50)\n",
        "    print(f\"[Validation]\\t Loss: {loss_epoch / len(val_loader)}\\t Accuracy: {accuracy_epoch / len(val_loader)}\")\n",
        "    loss_epoch_list.append(loss_epoch)\n",
        "print(\"Training successfully completed\")\n",
        "\n",
        "\n",
        "\n",
        "# final testing\n",
        "loss_epoch, accuracy_epoch = test(device, test_loader,resnet50)\n",
        "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")\n",
        "plt.plot(loss_epoch_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/50]\t Train Loss: 1.5648181949343\t Train Accuracy: 0.3354747386759582\n",
            "[Validation]\t Loss: 1.5706329345703125\t Accuracy: 0.21739130434782608\n",
            "Epoch [1/50]\t Train Loss: 1.4455522298812866\t Train Accuracy: 0.5552047038327526\n",
            "[Validation]\t Loss: 1.4774521589279175\t Accuracy: 0.4782608695652174\n",
            "Epoch [2/50]\t Train Loss: 1.3669523000717163\t Train Accuracy: 0.6314786585365854\n",
            "[Validation]\t Loss: 1.4023669958114624\t Accuracy: 0.5652173913043478\n",
            "Epoch [3/50]\t Train Loss: 1.3032126256397791\t Train Accuracy: 0.7384581881533101\n",
            "[Validation]\t Loss: 1.3437469005584717\t Accuracy: 0.5652173913043478\n",
            "Epoch [4/50]\t Train Loss: 1.2927040031978063\t Train Accuracy: 0.6543445121951219\n",
            "[Validation]\t Loss: 1.2705613374710083\t Accuracy: 0.6956521739130435\n",
            "Epoch [5/50]\t Train Loss: 1.2562891585486275\t Train Accuracy: 0.7488022648083623\n",
            "[Validation]\t Loss: 1.2312811613082886\t Accuracy: 0.7391304347826086\n",
            "Epoch [6/50]\t Train Loss: 1.2154316220964705\t Train Accuracy: 0.7657883275261324\n",
            "[Validation]\t Loss: 1.204219102859497\t Accuracy: 0.7391304347826086\n",
            "Epoch [7/50]\t Train Loss: 1.1981516224997384\t Train Accuracy: 0.7846254355400697\n",
            "[Validation]\t Loss: 1.2101612091064453\t Accuracy: 0.7391304347826086\n",
            "Epoch [8/50]\t Train Loss: 1.1897540092468262\t Train Accuracy: 0.7913218641114982\n",
            "[Validation]\t Loss: 1.178920030593872\t Accuracy: 0.7391304347826086\n",
            "Epoch [9/50]\t Train Loss: 1.1696410860334123\t Train Accuracy: 0.8116833623693379\n",
            "[Validation]\t Loss: 1.1765564680099487\t Accuracy: 0.7391304347826086\n",
            "Epoch [10/50]\t Train Loss: 1.1480188880647932\t Train Accuracy: 0.8056946864111498\n",
            "[Validation]\t Loss: 1.1654711961746216\t Accuracy: 0.7391304347826086\n",
            "Epoch [11/50]\t Train Loss: 1.130598885672433\t Train Accuracy: 0.8815875435540069\n",
            "[Validation]\t Loss: 1.1585773229599\t Accuracy: 0.782608695652174\n",
            "Epoch [12/50]\t Train Loss: 1.1177429131099157\t Train Accuracy: 0.8429333623693379\n",
            "[Validation]\t Loss: 1.1559648513793945\t Accuracy: 0.6956521739130435\n",
            "Epoch [13/50]\t Train Loss: 1.0882593733923775\t Train Accuracy: 0.8962325783972125\n",
            "[Validation]\t Loss: 1.1422598361968994\t Accuracy: 0.8260869565217391\n",
            "Epoch [14/50]\t Train Loss: 1.0747592278889246\t Train Accuracy: 0.9098976480836237\n",
            "[Validation]\t Loss: 1.1301864385604858\t Accuracy: 0.782608695652174\n",
            "Epoch [15/50]\t Train Loss: 1.0620059285845076\t Train Accuracy: 0.9225827526132404\n",
            "[Validation]\t Loss: 1.116695523262024\t Accuracy: 0.8695652173913043\n",
            "Epoch [16/50]\t Train Loss: 1.056916322026934\t Train Accuracy: 0.9324912891986062\n",
            "[Validation]\t Loss: 1.1065889596939087\t Accuracy: 0.7391304347826086\n",
            "Epoch [17/50]\t Train Loss: 1.0527604818344116\t Train Accuracy: 0.929551393728223\n",
            "[Validation]\t Loss: 1.1084582805633545\t Accuracy: 0.8695652173913043\n",
            "Epoch [18/50]\t Train Loss: 1.037013258252825\t Train Accuracy: 0.9305313588850174\n",
            "[Validation]\t Loss: 1.1030328273773193\t Accuracy: 0.8260869565217391\n",
            "Epoch [19/50]\t Train Loss: 1.0318572180611747\t Train Accuracy: 0.9232905052264808\n",
            "[Validation]\t Loss: 1.0987251996994019\t Accuracy: 0.8260869565217391\n",
            "Epoch [20/50]\t Train Loss: 1.0152692539351327\t Train Accuracy: 0.9416920731707317\n",
            "[Validation]\t Loss: 1.0974022150039673\t Accuracy: 0.8260869565217391\n",
            "Epoch [21/50]\t Train Loss: 1.0088095579828535\t Train Accuracy: 0.953125\n",
            "[Validation]\t Loss: 1.0950992107391357\t Accuracy: 0.8260869565217391\n",
            "Epoch [22/50]\t Train Loss: 1.0060850041253226\t Train Accuracy: 0.9503484320557491\n",
            "[Validation]\t Loss: 1.0924614667892456\t Accuracy: 0.8260869565217391\n",
            "Epoch [23/50]\t Train Loss: 1.0078080892562866\t Train Accuracy: 0.9518728222996515\n",
            "[Validation]\t Loss: 1.088606834411621\t Accuracy: 0.8695652173913043\n",
            "Epoch [24/50]\t Train Loss: 1.0085447090012687\t Train Accuracy: 0.9414198606271776\n",
            "[Validation]\t Loss: 1.0842883586883545\t Accuracy: 0.8695652173913043\n",
            "Epoch [25/50]\t Train Loss: 1.0019776565687997\t Train Accuracy: 0.9439242160278746\n",
            "[Validation]\t Loss: 1.0994547605514526\t Accuracy: 0.8260869565217391\n",
            "Epoch [26/50]\t Train Loss: 1.00324513231005\t Train Accuracy: 0.960801393728223\n",
            "[Validation]\t Loss: 1.0798989534378052\t Accuracy: 0.8695652173913043\n",
            "Epoch [27/50]\t Train Loss: 0.9945178883416312\t Train Accuracy: 0.960529181184669\n",
            "[Validation]\t Loss: 1.0957549810409546\t Accuracy: 0.8260869565217391\n",
            "Epoch [28/50]\t Train Loss: 1.0013241512434823\t Train Accuracy: 0.9573170731707317\n",
            "[Validation]\t Loss: 1.0826367139816284\t Accuracy: 0.8695652173913043\n",
            "Epoch [29/50]\t Train Loss: 0.9864600471087864\t Train Accuracy: 0.9575892857142857\n",
            "[Validation]\t Loss: 1.0808995962142944\t Accuracy: 0.9130434782608695\n",
            "Epoch [30/50]\t Train Loss: 0.978808581829071\t Train Accuracy: 0.9709821428571429\n",
            "[Validation]\t Loss: 1.0894595384597778\t Accuracy: 0.8260869565217391\n",
            "Epoch [31/50]\t Train Loss: 0.9836780599185398\t Train Accuracy: 0.9620535714285714\n",
            "[Validation]\t Loss: 1.0872803926467896\t Accuracy: 0.8260869565217391\n",
            "Epoch [32/50]\t Train Loss: 0.9792366198131016\t Train Accuracy: 0.9642857142857143\n",
            "[Validation]\t Loss: 1.0906838178634644\t Accuracy: 0.8695652173913043\n",
            "Epoch [33/50]\t Train Loss: 0.9896141886711121\t Train Accuracy: 0.9630335365853658\n",
            "[Validation]\t Loss: 1.0773051977157593\t Accuracy: 0.9130434782608695\n",
            "Epoch [34/50]\t Train Loss: 0.9737417953354972\t Train Accuracy: 0.9640135017421603\n",
            "[Validation]\t Loss: 1.0933598279953003\t Accuracy: 0.8695652173913043\n",
            "Epoch [35/50]\t Train Loss: 0.9813597883496966\t Train Accuracy: 0.960529181184669\n",
            "[Validation]\t Loss: 1.0887517929077148\t Accuracy: 0.8260869565217391\n",
            "Epoch [36/50]\t Train Loss: 0.9726454615592957\t Train Accuracy: 0.9716898954703833\n",
            "[Validation]\t Loss: 1.0808528661727905\t Accuracy: 0.8695652173913043\n",
            "Epoch [37/50]\t Train Loss: 0.9683069927351815\t Train Accuracy: 0.9674978222996515\n",
            "[Validation]\t Loss: 1.0804121494293213\t Accuracy: 0.8260869565217391\n",
            "Epoch [38/50]\t Train Loss: 0.9726555517741612\t Train Accuracy: 0.9697299651567944\n",
            "[Validation]\t Loss: 1.1017969846725464\t Accuracy: 0.8260869565217391\n",
            "Epoch [39/50]\t Train Loss: 0.9649736455508641\t Train Accuracy: 0.9799107142857143\n",
            "[Validation]\t Loss: 1.0792746543884277\t Accuracy: 0.8260869565217391\n",
            "Epoch [40/50]\t Train Loss: 0.966098598071507\t Train Accuracy: 0.9754464285714286\n",
            "[Validation]\t Loss: 1.09465754032135\t Accuracy: 0.8260869565217391\n",
            "Epoch [41/50]\t Train Loss: 0.9666377476283482\t Train Accuracy: 0.9719621080139372\n",
            "[Validation]\t Loss: 1.0877869129180908\t Accuracy: 0.8695652173913043\n",
            "Epoch [42/50]\t Train Loss: 0.9624576142856053\t Train Accuracy: 0.9796385017421603\n",
            "[Validation]\t Loss: 1.0746041536331177\t Accuracy: 0.8695652173913043\n",
            "Epoch [43/50]\t Train Loss: 0.957990322794233\t Train Accuracy: 0.9786585365853658\n",
            "[Validation]\t Loss: 1.083593726158142\t Accuracy: 0.8260869565217391\n",
            "Epoch [44/50]\t Train Loss: 0.9540759665625436\t Train Accuracy: 0.9821428571428571\n",
            "[Validation]\t Loss: 1.0743625164031982\t Accuracy: 0.8695652173913043\n",
            "Epoch [45/50]\t Train Loss: 0.9595086744853428\t Train Accuracy: 0.976154181184669\n",
            "[Validation]\t Loss: 1.0819900035858154\t Accuracy: 0.8260869565217391\n",
            "Epoch [46/50]\t Train Loss: 0.9597455774034772\t Train Accuracy: 0.9774063588850174\n",
            "[Validation]\t Loss: 1.0906909704208374\t Accuracy: 0.782608695652174\n",
            "Epoch [47/50]\t Train Loss: 0.9540038619722638\t Train Accuracy: 0.984375\n",
            "[Validation]\t Loss: 1.0690276622772217\t Accuracy: 0.8695652173913043\n",
            "Epoch [48/50]\t Train Loss: 0.9610745821680341\t Train Accuracy: 0.9719621080139372\n",
            "[Validation]\t Loss: 1.0904771089553833\t Accuracy: 0.8260869565217391\n",
            "Epoch [49/50]\t Train Loss: 0.9523496202060154\t Train Accuracy: 0.9821428571428571\n",
            "[Validation]\t Loss: 1.0811713933944702\t Accuracy: 0.8695652173913043\n",
            "Training successfully completed\n",
            "[FINAL]\t Loss: 1.0731581449508667\t Accuracy: 0.875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f69f6c98f98>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sNK6ns-E317"
      },
      "source": [
        "#Saving the Models\n",
        "torch.save(resnet50, '/content/drive/My Drive/Action_Recognition/Models/resnet50_1.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5rIkQNf7IzO",
        "outputId": "22d4ee71-e246-44ab-82f5-1304b0a15b0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss_epoch, accuracy_epoch = validate(device, val_loader, resnet50)\n",
        "print(f\"[FINAL]\\t Loss: {loss_epoch / len(val_loader)}\\t Accuracy: {accuracy_epoch / len(val_loader)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[FINAL]\t Loss: 1.0811713933944702\t Accuracy: 0.8695652173913043\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XogPDCL_A03",
        "outputId": "181e877a-009b-4f96-fa17-0ed728dbb940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "loss_epoch, accuracy_epoch = test(device, test_loader,resnet50)\n",
        "print(f\"[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[FINAL]\t Loss: 1.0731583833694458\t Accuracy: 0.875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}